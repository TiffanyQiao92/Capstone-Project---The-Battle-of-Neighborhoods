{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a href=\"https://cognitiveclass.ai\"><img src = \"https://ibm.box.com/shared/static/9gegpsmnsoo25ikkbl4qzlvlyjbgxs5x.png\" width = 400> </a>"},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"# Capstone Project - The Battle of the Neighborhoods (Week 2)\n### Applied Data Science Capstone by IBM/Coursera"},{"metadata":{},"cell_type":"markdown","source":"## Table of contents\n* [Introduction: Business Problem](#introduction)\n* [Data](#data)\n* [Methodology](#methodology)\n* [Analysis](#analysis)\n* [Results and Discussion](#results)\n* [Conclusion](#conclusion)"},{"metadata":{},"cell_type":"markdown","source":"\n\n## Introduction<a name=\"introduction\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Background<a name=\"Background\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Asian food is growing stronger in France lately. Asian restaurants are very often crowded especially in Paris area. \n\nIn Paris center and ‘little crown’, Vietnamese baguettes and Bubble tea are opening everywhere, and are always full whatever is the hour.  \n\nThis project aims to estimate the best localization to open such a business in Versailles city, just nearby Paris.\n\nPrior launching any restaurant, it’s important to know if the business as a good opportunity. In order to do so, this report will try to gather data about other restaurant localization, competitors and best localization. \n\nThese data could be use for a business plan afterward"},{"metadata":{},"cell_type":"markdown","source":"### Problem <a name=\"Problem\"></a>"},{"metadata":{},"cell_type":"markdown","source":"As the goal of this is to create a business plan in the end, we need to make sure data from api are correct. We also need to check that customer could be interested in this specific business. \n\nIn order to do so, a survey in Paris and Versailles will be done in addition to data gathering. I’ll go in the cities and check at different hours if restaurants are working, if streets are full and so on, and what king of restaurant works well. This survey will allow to validate the data analysis done here."},{"metadata":{},"cell_type":"markdown","source":"### Interest  <a name=\"Interest\"></a>"},{"metadata":{},"cell_type":"markdown","source":"This study can be used by anyone interested by opening a restaurant. Or any other business. \n\nMaybe they will need to modify some data. \n\n**Personal interest**:\n\nActually, I plan to open this business, so this study is done very seriously, the survey also. This study is going to be a part of a business plan to give to bank in order to optain a mortgage to start a business."},{"metadata":{},"cell_type":"markdown","source":"## Data <a name=\"data\"></a>"},{"metadata":{},"cell_type":"markdown","source":"This notebook is highly inspirated by the template given in the course. I will keep the idea of clustering the city by area and then plot heatmap to find better area.\n\nI will change some data:\n* Country/City: France\n* Goal: Open a restaurant/little shop for workers in weekday and maybe saturday\n\nSo, I will cross data from working days, and localisations.\n\nI will use the following API:\n* Foursquare API: to find restaurant/venues\n* Google API: reverse geolocalisation"},{"metadata":{},"cell_type":"markdown","source":"### Neighborhood Candidates\n\nLet's create latitude & longitude coordinates for centroids of our candidate neighborhoods. We will create a grid of cells covering our area of interest which is aprox. 1.5km killometers centered around **Versailles** city center.\n\nLet's first find the latitude & longitude of Versailles city center, using specific, well known address and Google Maps geocoding API.\n\nWe'll consider the Prefecture to be the city center, as a lot of companies are around."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T04:43:12.862788Z","start_time":"2020-01-19T04:43:12.859788Z"}},"cell_type":"markdown","source":"#### Imports"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:34.664874Z","start_time":"2020-01-19T09:43:32.758856Z"},"trusted":true},"cell_type":"code","source":"# This file contains all my ids for foursquare and google\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nCLIENT_ID = user_secrets.get_secret(\"CLIENT_ID\")\nCLIENT_SECRET = user_secrets.get_secret(\"CLIENT_SECRET\")\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\n\n# Others imports:\nfrom IPython.display import Image\nimport pickle\nimport json\nimport requests\nimport folium\nimport pandas as pd\n\n# !pip install shapely\nimport shapely.geometry\n\n# !pip install pyproj\nimport pyproj\n\nimport math\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Basics functions"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:35.228882Z","start_time":"2020-01-19T09:43:34.665874Z"},"trusted":true},"cell_type":"code","source":"def get_coordinates(api_key, address, verbose=False):\n    try:\n        url = 'https://maps.googleapis.com/maps/api/geocode/json?key={}&address={}'.format(api_key, address)\n        response = requests.get(url).json()\n        if verbose:\n            print('Google Maps API JSON result =>', response)\n        results = response['results']\n        geographical_data = results[0]['geometry']['location'] # get geographical coordinates\n        lat = geographical_data['lat']\n        lon = geographical_data['lng']\n        return [lat, lon]\n    except:\n        return [None, None]\n    \naddress = 'Préfecture de Versailles, Versailles, Frances'\nVersailles_center = get_coordinates(GOOGLE_API_KEY, address)\nprint('Coordinate of {}: {}'.format(address, Versailles_center))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's create a grid of area candidates, equaly spaced, centered around city center and within ~1.5km from Prefecture. Our neighborhoods will be defined as circular areas with a radius of 100 meters, so our neighborhood centers will be 200 meters apart.\n\nTo accurately calculate distances we need to create our grid of locations in Cartesian 2D coordinate system which allows us to calculate distances in meters (not in latitude/longitude degrees). Then we'll project those coordinates back to latitude/longitude degrees to be shown on Folium map. So let's create functions to convert between WGS84 spherical coordinate system (latitude/longitude degrees) and UTM Cartesian coordinate system (X/Y coordinates in  meters)."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:35.246886Z","start_time":"2020-01-19T09:43:35.230882Z"},"trusted":true},"cell_type":"code","source":"def lonlat_to_xy(lon, lat):\n    proj_latlon = pyproj.Proj(proj='latlong',datum='WGS84')\n    proj_xy = pyproj.Proj(proj=\"utm\", zone=33, datum='WGS84')\n    xy = pyproj.transform(proj_latlon, proj_xy, lon, lat)\n    return xy[0], xy[1]\n\ndef xy_to_lonlat(x, y):\n    proj_latlon = pyproj.Proj(proj='latlong',datum='WGS84')\n    proj_xy = pyproj.Proj(proj=\"utm\", zone=33, datum='WGS84')\n    lonlat = pyproj.transform(proj_xy, proj_latlon, x, y)\n    return lonlat[0], lonlat[1]\n\ndef calc_xy_distance(x1, y1, x2, y2):\n    dx = x2 - x1\n    dy = y2 - y1\n    return math.sqrt(dx*dx + dy*dy)\n\nprint('Coordinate transformation check')\nprint('-------------------------------')\nprint('Versailles center longitude={}, latitude={}'.format(Versailles_center[1], Versailles_center[0]))\nx, y = lonlat_to_xy(Versailles_center[1], Versailles_center[0])\nprint('Versailles center UTM X={}, Y={}'.format(x, y))\nlo, la = xy_to_lonlat(x, y)\nprint('Versailles center longitude={}, latitude={}'.format(lo, la))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### City partitionning"},{"metadata":{},"cell_type":"markdown","source":"Let's create a **hexagonal grid of cells**: we offset every other row, and adjust vertical row spacing so that **every cell center is equally distant from all it's neighbors**."},{"metadata":{},"cell_type":"markdown","source":"Let's visualize the data we have so far: city center location and candidate neighborhood centers:"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:36.131085Z","start_time":"2020-01-19T09:43:35.247885Z"},"trusted":true},"cell_type":"code","source":"Versailles_center_x, Versailles_center_y = lonlat_to_xy(Versailles_center[1], Versailles_center[0]) # City center in Cartesian coordinates\nnb_k = 10\nradius = 100\nk = math.sqrt(3) / 2 # Vertical offset for hexagonal grid cells\nx_min = Versailles_center_x - radius*10\nx_step = radius*2\ny_min = Versailles_center_y - radius*2 - (int(nb_k/k)*k*radius*2 - radius*10)/2\ny_step = radius*2 * k \n\nlatitudes = []\nlongitudes = []\ndistances_from_center = []\nxs = []\nys = []\nfor i in range(0, int(nb_k/k)):\n    y = y_min + i * y_step\n    x_offset = radius if i%2==0 else 0\n    for j in range(0, nb_k):\n        x = x_min + j * x_step + x_offset\n        distance_from_center = calc_xy_distance(Versailles_center_x, Versailles_center_y, x, y)\n        if (distance_from_center <= 6001):\n            lon, lat = xy_to_lonlat(x, y)\n            latitudes.append(lat)\n            longitudes.append(lon)\n            distances_from_center.append(distance_from_center)\n            xs.append(x)\n            ys.append(y)\n            \nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor lat, lon in zip(latitudes, longitudes):\n    folium.Circle([lat, lon], radius=radius, color='blue', fill=False).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK, we now have the coordinates of centers of neighborhoods/areas to be evaluated, equally spaced (distance from every point to it's neighbors is exactly the same) and within ~1.5km from Prefecture. \n\nLet's now use Google Maps API to get approximate addresses of those locations."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:36.4615Z","start_time":"2020-01-19T09:43:36.132085Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"def get_address(api_key, latitude, longitude, verbose=False):\n    try:\n        url = 'https://maps.googleapis.com/maps/api/geocode/json?key={}&latlng={},{}'.format(api_key, latitude, longitude)\n        response = requests.get(url).json()\n        if verbose:\n            print('Google Maps API JSON result =>', response)\n        results = response['results']\n        address = results[0]['formatted_address']\n        return address\n    except:\n        return None\n\naddr = get_address(GOOGLE_API_KEY, Versailles_center[0], Versailles_center[1])\nprint('Reverse geocoding check')\nprint('-----------------------')\nprint('Address of [{}, {}] is: {}'.format(Versailles_center[0], Versailles_center[1], addr))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:36.470502Z","start_time":"2020-01-19T09:43:36.4625Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"addresses = []\ncompteur = 0\n\ndf_locations = pd.DataFrame()\nloaded = False\ntry:\n    with open('locations.pkl', 'rb') as f:\n        df_locations = pickle.load(f)\n    print('Location data loaded from pickle.')\n    loaded = True\nexcept:\n    pass\n\n\nif not loaded:\n    print('Obtaining location addresses: ', end='')\n    for lat, lon in zip(latitudes, longitudes):\n        compteur = compteur + 1\n        address = get_address(GOOGLE_API_KEY, lat, lon)\n        if address is None:\n            address = 'NO ADDRESS'\n        address = address.replace(', France', '') # We don't need country part of address\n        addresses.append(address)\n        if compteur > 500:\n            print(\"Urgency exit\")\n            break\n    #     print(compteur)\n        print(' .', end='')\n    print(' done.')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:36.480504Z","start_time":"2020-01-19T09:43:36.471502Z"},"trusted":true},"cell_type":"code","source":"if not loaded:\n    addresses","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking good. Let's now place all this into a Pandas dataframe."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:36.497508Z","start_time":"2020-01-19T09:43:36.483506Z"},"trusted":true},"cell_type":"code","source":"\nif not loaded:\n    df_locations = pd.DataFrame({'Address': addresses,\n                                 'Latitude': latitudes,\n                                 'Longitude': longitudes,\n                                 'X': xs,\n                                 'Y': ys,\n                                 'Distance from center': distances_from_center})\n\ndf_locations.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"...and let's now save/persist this data into local file."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:36.50451Z","start_time":"2020-01-19T09:43:36.499509Z"},"trusted":true},"cell_type":"code","source":"df_locations.to_pickle('./locations.pkl')    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Methodology <a name=\"methodology\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Foursquare\nNow that we have our location candidates, let's use Foursquare API to get info on restaurants in each neighborhood.\n\nWe're interested in venues in 'food' category, but only the ones who can be competitors, this mean food truck, quick food, take away, healthy, not restaurant taking too long.\n\n**We will also list all companies and university to evaluate the customer pool**."},{"metadata":{},"cell_type":"markdown","source":"Foursquare credentials are defined in hidden cell bellow."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:36.513512Z","start_time":"2020-01-19T09:43:36.50551Z"},"trusted":true},"cell_type":"code","source":"foursquare_client_id = CLIENT_ID\nfoursquare_client_secret = CLIENT_SECRET","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:43:36.528516Z","start_time":"2020-01-19T09:43:36.515512Z"},"trusted":true},"cell_type":"code","source":"# Category IDs corresponding to Italian restaurants were taken from Foursquare web site \n# (https://developer.foursquare.com/docs/resources/categories):\n\nfood_category = '4d4b7105d754a06374d81259' # 'Root' category for all food-related venues\n\n# We will add some asian categories, and also take away food, and healthy food. These category are the one that\n# may be competitor\nasian_restaurant_categories = ['4bf58dd8d48988d142941735','4bf58dd8d48988d145941735', '4bf58dd8d48988d111941735',\n                                '4bf58dd8d48988d1d2941735', '4bf58dd8d48988d1d1941735', '4bf58dd8d48988d14a941735',\n                              '56aa371be4b08b9a8d57350b', '4bf58dd8d48988d1cb941735', '4bf58dd8d48988d1e0931735',\n                              '4bf58dd8d48988d16c941735', '4bf58dd8d48988d16f941735', '5283c7b4e4b094cb91ec88d7',\n                              '4bf58dd8d48988d1bd941735', '4bf58dd8d48988d1c5941735', '4bf58dd8d48988d1c7941735']\n\ndef is_restaurant(categories, specific_filter=None):\n    restaurant_words = ['Restaurant', 'restaurant', 'diner', 'taverna', 'steakhouse', 'Brasserie', 'Creperie', 'Café',\n                       'Truck', 'Sandwich', 'Pizza']\n    restaurant = False\n    specific = False\n    for c in categories:\n        category_name = c[0].lower()\n        category_id = c[1]\n        for r in restaurant_words:\n            if r in category_name:\n                restaurant = True\n        if 'fast food' in category_name:\n            restaurant = False\n        if not(specific_filter is None) and (category_id in specific_filter):\n            specific = True\n            restaurant = True\n    return restaurant, specific\n\ndef get_categories(categories):\n    return [(cat['name'], cat['id']) for cat in categories]\n\ndef format_address(location):\n    address = ', '.join(location['formattedAddress'])\n    return address\n\ndef get_venues_near_location(lat, lon, category, client_id, client_secret, radius=500, limit=100):\n    version = '20180724'\n    url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&categoryId={}&radius={}&limit={}'.format(\n        client_id, client_secret, version, lat, lon, category, radius, limit)\n    try:\n        results = requests.get(url).json()['response']['groups'][0]['items']\n        venues = [(item['venue']['id'],\n                   item['venue']['name'],\n                   get_categories(item['venue']['categories']),\n                   (item['venue']['location']['lat'], item['venue']['location']['lng']),\n                   format_address(item['venue']['location']),\n                   item['venue']['location']['distance']) for item in results]        \n    except:\n        venues = []\n    return venues","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:44:10.96714Z","start_time":"2020-01-19T09:43:36.529516Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"# Let's now go over our neighborhood locations and get nearby restaurants; we'll also maintain \n# a dictionary of all found restaurants and all found italian restaurants\n\ndef get_restaurants(lats, lons):\n    from tqdm.autonotebook import tqdm\n    tqdm.pandas()\n    restaurants = {}\n    asian_restaurants = {}\n    location_restaurants = []\n\n    print('Obtaining venues around candidate locations:', end='')\n    pbar = tqdm(total=len(lats))\n    for lat, lon in zip(lats, lons):\n        # Using radius=350 to meke sure we have overlaps/full coverage so we don't miss any restaurant (we're using dictionaries to remove any duplicates resulting from area overlaps)\n        venues = get_venues_near_location(lat, lon, food_category, foursquare_client_id, \n                                          foursquare_client_secret, radius=350, limit=100)\n#         with open('1. venues.txt', 'w') as outfile:\n#             json.dump(venues, outfile)\n        area_restaurants = []\n#         print(venues)\n        \n        for venue in venues:            \n#             with open('2. venue.txt', 'w') as outfile:\n#                 json.dump(venue, outfile)\n            venue_id = venue[0]\n            venue_name = venue[1]\n            venue_categories = venue[2]\n            venue_latlon = venue[3]\n            venue_address = venue[4]\n            venue_distance = venue[5]\n            is_res, is_asian = is_restaurant(venue_categories, specific_filter=asian_restaurant_categories)\n            if is_res:\n                x, y = lonlat_to_xy(venue_latlon[1], venue_latlon[0])\n                restaurant = (venue_id, venue_name, venue_latlon[0], venue_latlon[1], venue_address, \n                              venue_distance, is_asian, x, y)\n#                 print(\"\\n\" + str(restaurant))\n                if venue_distance<=100:\n                    area_restaurants.append(restaurant)\n                restaurants[venue_id] = restaurant\n                if is_asian:\n                    asian_restaurants[venue_id] = restaurant\n        pbar.update(1)        \n        \n        location_restaurants.append(area_restaurants)\n#         print(' .', end='')\n    pbar.close()\n#     print(' done.')\n    return restaurants, asian_restaurants, location_restaurants\n\n# Try to load from local file system in case we did this before\nrestaurants = {}\nasian_restaurants = {}\nlocation_restaurants = []\nloaded = False\ntry:\n    with open('restaurants_350.pkl', 'rb') as f:\n        restaurants = pickle.load(f)\n    with open('asian_restaurants_350.pkl', 'rb') as f:\n        asian_restaurants = pickle.load(f)\n    with open('location_restaurants_350.pkl', 'rb') as f:\n        location_restaurants = pickle.load(f)\n    print('Restaurant data loaded.')\n    loaded = True\nexcept:\n    pass\n\n# If load failed use the Foursquare API to get the data\nif not loaded:\n    restaurants, asian_restaurants, location_restaurants = get_restaurants(latitudes, longitudes)\n    \n    # Let's persists this in local file system\n    with open('restaurants_350.pkl', 'wb') as f:\n        pickle.dump(restaurants, f)\n    with open('asian_restaurants_350.pkl', 'wb') as f:\n        pickle.dump(asian_restaurants, f)\n    with open('location_restaurants_350.pkl', 'wb') as f:\n        pickle.dump(location_restaurants, f)\n        ","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:44:10.979141Z","start_time":"2020-01-19T09:44:10.968139Z"},"trusted":true},"cell_type":"code","source":"import numpy as np\n\nprint('Total number of restaurants:', len(restaurants))\nprint('Total number of Asian restaurants:', len(asian_restaurants))\nprint('Percentage of Asian restaurants: {:.2f}%'.format(len(asian_restaurants) / len(restaurants) * 100))\nprint('Average number of restaurants in neighborhood:', np.array([len(r) for r in location_restaurants]).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Restaurants visualization"},{"metadata":{},"cell_type":"markdown","source":"Let's now see all the collected restaurants in our area of interest on map, and let's also show Asian restaurants in different color."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:44:11.892348Z","start_time":"2020-01-19T09:44:10.980142Z"},"trusted":true},"cell_type":"code","source":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor res in restaurants.values():\n    lat = res[2]; lon = res[3]\n    is_asian = res[6]\n    color = 'red' if is_asian else 'blue'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, on this map we can see all potential competitors, take away restaurant, healthy restaurant. Asian restaurant are in red.\n\nNo we need to analyse companies/university localisation and cluster and cross both analysis.\n\nWe need to remember that the target are worker wanting to buy healthy fast food for breakfast and lunch, we don't aim the evening. Also, another target can be universities."},{"metadata":{},"cell_type":"markdown","source":"#### Universities visualization"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:44:46.912618Z","start_time":"2020-01-19T09:44:11.893348Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"# 'Root' category for all universities venues\nuniv_category = ['4d4b7105d754a06372d81259']\n\ndef get_meta_venues(lats, lons, meta_category):\n    from tqdm.autonotebook import tqdm\n    tqdm.pandas()\n    meta_venues = {}\n    neighborhoods_venues = []\n\n#     print('Obtaining venues around candidate locations:', end='')\n    pbar = tqdm(total=len(lats), desc = 'Obtaining venues', unit= ' coord')\n    for lat, lon in zip(lats, lons):\n        # Using radius=350 to meke sure we have overlaps/full coverage so we don't miss any restaurant (we're using dictionaries to remove any duplicates resulting from area overlaps)\n        area_meta_venues = []\n        for i, category in enumerate(meta_category):\n            venues = get_venues_near_location(lat, lon, category, foursquare_client_id, \n                                              foursquare_client_secret, radius=350, limit=100)\n            for venue in venues:\n                venue_id = venue[0]\n                venue_name = venue[1]\n                venue_categories = venue[2]\n                venue_latlon = venue[3]\n                venue_address = venue[4]\n                venue_distance = venue[5]\n\n                x, y = lonlat_to_xy(venue_latlon[1], venue_latlon[0])\n                restaurant = (venue_id, venue_name, venue_latlon[0], venue_latlon[1], \n                              venue_address, venue_distance, is_asian, x, y)\n                if venue_distance<=100:\n                    area_meta_venues.append(restaurant)\n                meta_venues[venue_id] = restaurant\n\n            neighborhoods_venues.append(area_meta_venues)\n#         print(' .', end='')\n        pbar.update(1)\n    pbar.close()\n#     print(' done.')\n    return meta_venues, neighborhoods_venues\n\n\n\n# plantage = plantage # Just to make sure we won't go after this point\n\n# Try to load from local file system in case we did this before\nmeta_univ = {}\nneighborhoods_univ = []\nloaded = False\ntry:\n    with open('meta_univ_350.pkl', 'rb') as f:\n        meta_univ = pickle.load(f)\n    with open('neighborhoods_univ_350.pkl', 'rb') as f:\n        neighborhoods_univ = pickle.load(f)\n    print('Universities data loaded.')\n    loaded = True\nexcept:\n    pass\n\nif not loaded:\n    meta_univ, neighborhoods_univ = get_meta_venues(latitudes, longitudes, univ_category)\n    \n    # Let's persists this in local file system\n    with open('meta_univ_350.pkl', 'wb') as f:\n        pickle.dump(meta_univ, f)\n    with open('neighborhoods_univ_350.pkl', 'wb') as f:\n        pickle.dump(neighborhoods_univ, f)\n        \nprint('Total number of universities:', len(meta_univ))\nprint('Average number of universities in neighborhood:', np.array([len(r) for r in neighborhoods_univ]).mean())\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor res in meta_univ.values():\n    lat = res[2]; lon = res[3]\n    is_univ = res[6]\n    color = 'blue' \n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Companies visualization"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:47:10.627908Z","start_time":"2020-01-19T09:44:46.913618Z"},"trusted":true},"cell_type":"code","source":"# 'Root' category for all companies venues\ncompanies_category = ['4d4b7105d754a06375d81259', '4d4b7105d754a06378d81259', '4d4b7105d754a06379d81259',\n                     '4d4b7104d754a06370d81259']\n\n# Try to load from local file system in case we did this before\nmeta_company = {}\nneighborhoods_company = []\nloaded = False\ntry:\n    with open('meta_company_350.pkl', 'rb') as f:\n        meta_company = pickle.load(f)\n    with open('neighborhoods_company_350.pkl', 'rb') as f:\n        neighborhoods_company = pickle.load(f)\n    print('Companies data loaded.')\n    loaded = True\nexcept:\n    pass\n\nif not loaded:\n    meta_company, neighborhoods_company = get_meta_venues(latitudes, longitudes, companies_category)\n    \n    # Let's persists this in local file system\n    with open('meta_company_350.pkl', 'wb') as f:\n        pickle.dump(meta_company, f)\n    with open('neighborhoods_company_350.pkl', 'wb') as f:\n        pickle.dump(neighborhoods_company, f)\n        \nprint('Total number of companies:', len(meta_company))\nprint('Average number of companies in neighborhood:', np.array([len(r) for r in neighborhoods_company]).mean())\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor res in meta_company.values():\n    lat = res[2]; lon = res[3]\n    is_company = res[6]\n    color = 'red'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Global map of worker/students versus Restaurants"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:47:15.326969Z","start_time":"2020-01-19T09:47:10.628908Z"},"trusted":true},"cell_type":"code","source":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor res in meta_company.values():\n    lat = res[2]; lon = res[3]\n    color = 'green'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nfor res in meta_univ.values():\n    lat = res[2]; lon = res[3]\n    color = 'yellow'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nfor res in restaurants.values():\n    lat = res[2]; lon = res[3]\n    is_asian = res[6]\n    color = 'red' if is_asian else 'blue'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good, we have a map with the big companies and universities, we can then already see main areas with potential customers."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T05:54:24.144129Z","start_time":"2020-01-19T05:54:24.140129Z"},"trusted":true},"cell_type":"code","source":"Image(\"../input/versailles_size.PNG\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After visualization of data we can conclude:\n* Competitors are scattered around the city, but there are just a few real competitors (actually only one is doing Vietnamese baguette and Bubble tea in Versailles)\n* Very close to the prefecture there are just a few companies (in the 100/200m radius), they are 300m south and north.\n\nWe will now focus on spotting worker area more than competitors, we will try do determine where are clusters more of the worker.\n\nIn order to do that, we will use the **k mean clustering method**."},{"metadata":{},"cell_type":"markdown","source":"#### Creation and visualization of customer group:"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:25.761987Z","start_time":"2020-01-19T09:47:15.32797Z"},"trusted":true},"cell_type":"code","source":"# 'Root' category for all companies venues\ncustomer_category = ['4d4b7105d754a06375d81259', '4d4b7105d754a06378d81259', '4d4b7105d754a06379d81259',\n                     '4d4b7104d754a06370d81259', '4d4b7105d754a06372d81259']\n\n# Try to load from local file system in case we did this before\nmeta_customers = []\nneighborhoods_customers = []\nloaded = False\ntry:\n    with open('meta_customers_350.pkl', 'rb') as f:\n        meta_customers = pickle.load(f)\n    with open('neighborhoods_customers_350.pkl', 'rb') as f:\n        neighborhoods_customers = pickle.load(f)\n    print('Companies data loaded.')\n    loaded = True\nexcept:\n    pass\n\nif not loaded:\n    from tqdm.autonotebook import tqdm\n    pbar1 = tqdm(total=len(customer_category), desc = 'Cycling categories', unit= ' categories')\n    for category in customer_category:\n        meta_customer, neighborhoods_customer = get_meta_venues(latitudes, longitudes, [category])\n        meta_customers.append(meta_customer)\n        neighborhoods_customers.append(neighborhoods_customer)\n        pbar1.update(1)\n    pbar1.close()\n    \n    # Let's persists this in local file system\n    with open('meta_customers_350.pkl', 'wb') as f:\n        pickle.dump(meta_customers, f)\n    with open('neighborhoods_customers_350.pkl', 'wb') as f:\n        pickle.dump(neighborhoods_customers, f)\n        \nprint('Total number of customers:', len(meta_customers))\nprint('Average number of customers in neighborhood:', np.array([len(r) for r in neighborhoods_customers]).mean())\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor meta_customer in meta_customers:\n    for res in meta_customer.values():\n        lat = res[2]; lon = res[3]\n        color = 'red'\n        label = '{}'.format(res[1])\n        label = folium.Popup(label, parse_html=True)\n        folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                            popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysis <a name=\"analysis\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Let's perform some basic explanatory data analysis and derive some additional info from our raw data. First let's count the **number of business in every area candidate**:"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:25.770989Z","start_time":"2020-01-19T09:50:25.762987Z"},"trusted":true},"cell_type":"code","source":"counts = []\nfor i, neighborhoods_customer in enumerate(neighborhoods_customers):\n    counts.append([len(res) for res in neighborhoods_customers[i]])\nfinal_count= []\nlen(counts[0])\nfor m in range(len(counts[0])):\n    final_count.append(0)\n    for n in range(len(counts)):\n        final_count[m] = final_count[m] + counts[n][m]\nlen(final_count)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:25.790994Z","start_time":"2020-01-19T09:50:25.771989Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"# location_customers_count = [len(res) for res in neighborhoods_customers]\ncounts = []\nfor i, neighborhoods_customer in enumerate(neighborhoods_customers):\n    counts.append([len(res) for res in neighborhoods_customers[i]])\nlocation_customers_count= []\nlen(counts[0])\nfor m in range(len(counts[0])):\n    location_customers_count.append(0)\n    for n in range(len(counts)):\n        location_customers_count[m] = location_customers_count[m] + counts[n][m]\n\ndf_locations['Customers in area'] = location_customers_count\n\nprint('Average number of customers in every area with radius=100m:', np.array(location_customers_count).mean())\n\ndf_locations.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 10 first areas"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:25.802996Z","start_time":"2020-01-19T09:50:25.791994Z"},"trusted":true},"cell_type":"code","source":"df_locations.sort_values(by='Customers in area', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The mains areas are in the north of prefecture, usualy around 400/500m away, it's not a big surprise."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:25.811998Z","start_time":"2020-01-19T09:50:25.803997Z"},"trusted":true},"cell_type":"code","source":"restaurant_latlons = [[res[2], res[3]] for res in restaurants.values()]\n\ncustomers_latlons = []\nfor meta_customer in meta_customers:\n    customers_latlons.append([[res[2], res[3]] for res in meta_customer.values()])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:25.899018Z","start_time":"2020-01-19T09:50:25.815Z"},"trusted":true},"cell_type":"code","source":"from folium import plugins\nfrom folium.plugins import HeatMap\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles) #cartodbpositron cartodbdark_matter\nfor customers_latlon in customers_latlons:\n    HeatMap(customers_latlon).add_to(map_versailles)\n# folium.Marker(Versailles_center).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=100, fill=False, color='white').add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=300, fill=False, color='white').add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=500, fill=False, color='white').add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly identify **two big cluster, on north, on south**. \n\nLet's create another heatmap map showing **heatmap/density of restaurants**."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:25.991038Z","start_time":"2020-01-19T09:50:25.90102Z"},"trusted":true},"cell_type":"code","source":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles) #cartodbpositron cartodbdark_matter\nHeatMap(restaurant_latlons).add_to(map_versailles)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfolium.Marker([48.804394, 2.131718], popup='La boite a Bobun',\n    icon=folium.Icon(color='red', icon='info-sign')).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=100, fill=False, color='white').add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=300, fill=False, color='white').add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=500, fill=False, color='white').add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, the restaurants are also in this area, but if we look at the first map, we can see that **we almost have no competitors in this area**.\n\nThe only competitor is indicated in red, and actually they are **not making bubble tea**, and the sandwitch are not real vietnamese style."},{"metadata":{},"cell_type":"markdown","source":"#### Zoom north west"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:26.079059Z","start_time":"2020-01-19T09:50:25.993039Z"},"code_folding":[5],"trusted":true},"cell_type":"code","source":"from folium import plugins\nfrom folium.plugins import HeatMap\n\nmap_versailles = folium.Map(location=[48.806812, 2.131194], zoom_start=16)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles) #cartodbpositron cartodbdark_matter\nfor customers_latlon in customers_latlons:\n    HeatMap(customers_latlon).add_to(map_versailles)\n# folium.Marker(Versailles_center).add_to(map_versailles)\nfolium.Marker([48.804394, 2.131718], popup='La boite a Bobun',\n    icon=folium.Icon(color='red', icon='info-sign')).add_to(map_versailles)\nfolium.Marker([48.806350, 2.131048], popup='Good spot',\n    icon=folium.Icon(color='green')).add_to(map_versailles)\nfolium.Circle([48.806350, 2.131048], radius=300, color='white', fill=True, fill_opacity=0.4).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:26.157076Z","start_time":"2020-01-19T09:50:26.080059Z"},"trusted":true},"cell_type":"code","source":"map_versailles = folium.Map(location=[48.806812, 2.131194], zoom_start=16)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles) #cartodbpositron cartodbdark_matter\nHeatMap(restaurant_latlons).add_to(map_versailles)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfolium.Marker([48.804394, 2.131718], popup='La boite a Bobun',\n    icon=folium.Icon(color='red', icon='info-sign')).add_to(map_versailles)\nfolium.Marker([48.806350, 2.131048], popup='Good spot',\n    icon=folium.Icon(color='green')).add_to(map_versailles)\nfolium.Circle([48.806350, 2.131048], radius=300, color='white', fill=True, fill_opacity=0.4).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly identify here an area with a lot of customer and few competitors >>> See the **green marker**.\n\nThe white circle indicate an area 300m wide. We can see that a lot of worker are inside, and the main competitor is not in the center."},{"metadata":{},"cell_type":"markdown","source":"### K mean clustering\n\nLet's do the kmean clustering to see what will be the result."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:26.225092Z","start_time":"2020-01-19T09:50:26.159078Z"},"trusted":true},"cell_type":"code","source":"# We plot the area where we'll search for good localisation\nroi_x_min = Versailles_center_x -1000\nroi_y_max = Versailles_center_y\nroi_width = 1500\nroi_height = 1500\nroi_center_x = roi_x_min\nroi_center_y = roi_y_max\nroi_center_lon, roi_center_lat = xy_to_lonlat(roi_center_x, roi_center_y)\nroi_center = [roi_center_lat, roi_center_lon]\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfor customers_latlon in customers_latlons:\n    HeatMap(customers_latlon).add_to(map_versailles)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=700, color='white', fill=True, fill_opacity=0.4).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:50:27.729443Z","start_time":"2020-01-19T09:50:26.226092Z"},"trusted":true},"cell_type":"code","source":"k = math.sqrt(3) / 2 # Vertical offset for hexagonal grid cells\nnb_k = 20 #51 a la base\nx_step = 100\ny_step = 100 * k \nroi_y_min = roi_center_y - 700\n\nroi_latitudes = []\nroi_longitudes = []\nroi_xs = []\nroi_ys = []\nfor i in range(0, int(nb_k/k)):\n    y = roi_y_min + i * y_step\n    x_offset = (nb_k-1) if i%2==0 else 0\n    for j in range(0, 51):\n        x = roi_x_min + j * x_step + x_offset\n        d = calc_xy_distance(roi_center_x, roi_center_y, x, y)\n        if (d <= 2501):\n            lon, lat = xy_to_lonlat(x, y)\n            roi_latitudes.append(lat)\n            roi_longitudes.append(lon)\n            roi_xs.append(x)\n            roi_ys.append(y)\n\nprint(len(roi_latitudes), 'candidate neighborhood centers generated.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK. Now let's calculate two most important things for each location candidate: **number of restaurants in vicinity** (we'll use radius of **150 meters**) and **number of customers**."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:56:28.444173Z","start_time":"2020-01-19T09:56:28.29414Z"},"trusted":true},"cell_type":"code","source":"def count_restaurants_nearby(x, y, restaurants, radius=150):    \n    count = 0\n    for res in restaurants.values():\n        res_x = res[7]; res_y = res[8]\n        d = calc_xy_distance(x, y, res_x, res_y)\n        if d<=radius:\n            count += 1\n    return count\n\ndef find_nearest_restaurant(x, y, restaurants):\n    d_min = 100000\n    for res in restaurants.values():\n        res_x = res[7]; res_y = res[8]\n        d = calc_xy_distance(x, y, res_x, res_y)\n        if d<=d_min:\n            d_min = d\n    return d_min\n\ndef count_customers_nearby(x, y, customers, radius=150):    \n    count = 0\n    for meta_customer in meta_customers:\n        for res in meta_customer.values():\n            res_x = res[7]; res_y = res[8]\n            d = calc_xy_distance(x, y, res_x, res_y)\n            if d<=radius:\n                count += 1\n    return count\n\nroi_restaurant_counts = []\nroi_asian_restaurants = []\nroi_customer = []\n\nprint('Generating data on location candidates... ', end='')\nfor x, y in zip(roi_xs, roi_ys):\n    count = count_restaurants_nearby(x, y, restaurants, radius=100)\n    roi_restaurant_counts.append(count)\n    \n    distance = find_nearest_restaurant(x, y, asian_restaurants)\n    roi_asian_restaurants.append(distance)\n    \n    custom = count_customers_nearby(x, y, meta_customers)\n    roi_customer.append(custom)\nprint('done.')\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:56:30.964182Z","start_time":"2020-01-19T09:56:30.950179Z"},"trusted":true},"cell_type":"code","source":"# Let's put this into dataframe\ndf_roi_locations = pd.DataFrame({'Latitude':roi_latitudes,\n                                 'Longitude':roi_longitudes,\n                                 'X':roi_xs,\n                                 'Y':roi_ys,\n                                 'Restaurants nearby':roi_restaurant_counts,\n                                 'Distance to Asian restaurant':roi_asian_restaurants,\n                                 'Customers':roi_customer})\n\ndf_roi_locations.sort_values(by='Customers', ascending=False).head(10)\n# df_roi_locations.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK. Let us now **filter** those locations: we're interested only in **locations with no more than two restaurants in radius of 250 meters**, and **no asian restaurants in radius of 100 meters**, and **more than 10 customers**."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:56:34.099323Z","start_time":"2020-01-19T09:56:34.086321Z"},"trusted":true},"cell_type":"code","source":"good_res_count = np.array((df_roi_locations['Restaurants nearby']<=2))\nprint('Locations with no more than two restaurants nearby:', good_res_count.sum())\n\ngood_asi_distance = np.array(df_roi_locations['Distance to Asian restaurant']>=100)\nprint('Locations with no Asian restaurants within 400m:', good_asi_distance.sum())\n\ngood_custmer_count = np.array(df_roi_locations['Customers']>=10)\nprint('Locations with more than 10 customers:', good_custmer_count.sum())\n\ngood_locations = np.logical_and(good_custmer_count, good_res_count, good_asi_distance)\nprint('Locations with both conditions met:', good_locations.sum())\n\ndf_good_locations = df_roi_locations[good_locations]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how this looks on a map."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:56:36.392715Z","start_time":"2020-01-19T09:56:35.97462Z"},"trusted":true},"cell_type":"code","source":"good_latitudes = df_good_locations['Latitude'].values\ngood_longitudes = df_good_locations['Longitude'].values\n\ngood_locations = [[lat, lon] for lat, lon in zip(good_latitudes, good_longitudes)]\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles)\nHeatMap(restaurant_latlons).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=700, color='white', fill=True, fill_opacity=0.6).add_to(map_versailles)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, \n                        fill_color='blue', fill_opacity=1).add_to(map_versailles) \nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can identify two mains areas, one south, the other one north as expected.\n\nLet's see heatmap:"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:56:40.188671Z","start_time":"2020-01-19T09:56:39.781579Z"},"trusted":true},"cell_type":"code","source":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nHeatMap(good_locations, radius=35).add_to(map_versailles)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, \n                        fill_color='blue', fill_opacity=1).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking good. What we have now is a clear indication of zones with low number of restaurants in vicinity, and *no* Asian restaurants at all nearby, and good numbers of customers.\n\nLet us now **cluster** those locations to create **centers of zones containing good locations**. Those zones, their centers and addresses will be the final result of our analysis. "},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:56:44.205838Z","start_time":"2020-01-19T09:56:43.11059Z"},"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nnumber_of_clusters = 15\n\ngood_xys = df_good_locations[['X', 'Y']].values\nkmeans = KMeans(n_clusters=number_of_clusters, random_state=0).fit(good_xys)\n\ncluster_centers = [xy_to_lonlat(cc[0], cc[1]) for cc in kmeans.cluster_centers_]\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles)\nfor customers_latlon in customers_latlons:\n    HeatMap(customers_latlon).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=700, color='white', fill=True, fill_opacity=0.4).add_to(map_versailles)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lon, lat in cluster_centers:\n    folium.Circle([lat, lon], radius=80, color='green', fill=True, fill_opacity=0.25).add_to(map_versailles) \nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, fill_color='blue', \n                        fill_opacity=1).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad - our clusters represent groupings of most of the candidate locations and cluster centers are placed nicely in the middle of the zones 'rich' with location candidates.\n\nAddresses of those cluster centers will be a good starting point for exploring the neighborhoods to find the best possible location based on neighborhood specifics.\n\nLet's see those zones on a city map without heatmap, using shaded areas to indicate our clusters:"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:56:51.506102Z","start_time":"2020-01-19T09:56:50.664913Z"},"trusted":true},"cell_type":"code","source":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.Circle([lat, lon], radius=250, color='#00000000', fill=True, fill_color='#0066ff', \n                  fill_opacity=0.07).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, fill_color='blue', \n                        fill_opacity=1).add_to(map_versailles)\nfor lon, lat in cluster_centers:\n    folium.Circle([lat, lon], radius=80, color='green', fill=False).add_to(map_versailles) \nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's zoom in on candidate areas in **north, on the Marché Notre Dame**:"},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:56:54.716399Z","start_time":"2020-01-19T09:56:53.887212Z"},"trusted":true},"cell_type":"code","source":"map_versailles = folium.Map(location=[48.806620, 2.132041], zoom_start=16)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lon, lat in cluster_centers:\n    folium.Circle([lat, lon], radius=60, color='green', fill=False).add_to(map_versailles) \nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.Circle([lat, lon], radius=250, color='#0000ff00', fill=True, fill_color='#0066ff', \n                  fill_opacity=0.07).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, fill_color='blue', \n                        fill_opacity=1).add_to(map_versailles)\nmap_versailles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finaly, let's **reverse geocode those candidate area centers to get the addresses** which can be presented to stakeholders."},{"metadata":{"ExecuteTime":{"end_time":"2020-01-19T09:57:01.297021Z","start_time":"2020-01-19T09:56:57.056118Z"},"trusted":true},"cell_type":"code","source":"candidate_area_addresses = []\nprint('==============================================================')\nprint('Addresses of centers of areas recommended for further analysis')\nprint('==============================================================\\n')\nfor lon, lat in cluster_centers:\n    addr = get_address(GOOGLE_API_KEY, lat, lon).replace(', France', '')\n    candidate_area_addresses.append(addr)    \n    x, y = lonlat_to_xy(lon, lat)\n    d = calc_xy_distance(x, y, Versailles_center_x, Versailles_center_y)\n    print('{}{} => {:.1f}km from Prefecture'.format(addr, ' '*(50-len(addr)), d/1000))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results and Discussion <a name=\"results\"></a>"},{"metadata":{},"cell_type":"markdown","source":"This analysis shows that we must consider other criterias than just number of restaurant.\n\nVersailles is a little city, so the concentration of restaurant is quite high, in this analysis I tried to corrolate the number of restaurant and quantity of potential customer.\n\nIn opposit to  what I was thinking, the Prefecture area is not very crowded, mainly because building are big (French old style building, full of empty space and big garden).\n\nAlso, I was able to discover that there are not a lot of competitor on this business area, which is very good.\n\n15 good potential places are foud, I personnaly think that the one in the north is better.\n\nWe must just take care of one thing, I thing the api didn't return all data, we are missing a lot of companies, the map is still good, and the result can be trusted, but we should cross check data with other data source.\n\nIn order to be more accurate, it could be possible to give a weight to customers for example, a university with 1000 student would then weight more than a hair cut company with two employees."},{"metadata":{},"cell_type":"markdown","source":"## Conclusion <a name=\"conclusion\"></a>"},{"metadata":{},"cell_type":"markdown","source":"This project can be reused for other cities, just think about changing clustering size to adapt to your city.\n\nAlso, I have created/modify a huge quantity of function in order to adapt. \n\nIt's very far from being perfect, a lot of work can be done, other source of data can be found, but in the end the result seams to correlate with the real world, when we know the city, the area predicted seams correct."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"279.333px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}